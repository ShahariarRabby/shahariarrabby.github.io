<h1>COCO 2017 Object Detection Task</h1>
<p><img src="images/detection-splash.png" class="wide"/></p>
<p class="fontBig">The <a href="https://places-coco2017.github.io/#winners">Challenge Winners</a> have now been announced! Up-to-date results are on the <a href="#detection-leaderboard">detection leaderboard</a>. Note that the evaluation server on test-dev remains open for uploading of new results.</p>

<h1>1. Overview</h1>
<p>The COCO Object Detection Task is designed to push the state of the art in object detection forward. Teams are encouraged to compete in either (or both) of two object detection challenges: using bounding box output or object segmentation output. For full details of this task please see the <a href="#detection-eval">detection evaluation</a> page.</p>
<p>This task is part of the <a href="https://places-coco2017.github.io/">Joint COCO and Places Recognition Challenge Workshop</a> at ICCV 2017. For further details about the joint workshop please visit the workshop page. Participants are encouraged to participate in both the COCO and Places challenges. Please also see the related COCO <a href="#stuff-2017">stuff</a> and <a href="#keypoints-2017">keypoint</a> tasks.</p>
<p>The COCO train, validation, and test sets, containing more than 200,000 images and 80 object categories, are available on the <a href="#download">download</a> page. All object instances are annotated with a detailed segmentation mask. Annotations on the training and validation sets (with over 500,000 object instances segmented) are publicly available.</p>
<p>This is the third iteration of the detection task and it closely follows the <a href="#detection-2016">COCO 2016 Object Detection Task</a>. In particular, the same overall data and metrics are being used for this year's challenge. The mains differences are that now <b>(1) the test set only contains two splits: test-dev and test-challenge,</b> and <b>(2) the train/val sets are arranged differently</b>. Please see the <a href="#download">download</a> and <a href="#guidelines">guidelines</a> pages for details about the setup for the 2017 data and test splits.</p>

<h1>2. Dates</h1>
<div class="json">
  <div class="jsonktxt fontBlue">September 30, 2017</div><div class="jsonvtxt">Submission deadline (11:59 PST)</div>
  <div class="jsonktxt">October 15, 2017</div><div class="jsonvtxt">Challenge winners notified</div>
  <div class="jsonktxt">October 29, 2017</div><div class="jsonvtxt">Winners present at ICCV 2017 Workshop</div>
</div>

<h1>3. Organizers</h1>
<div>Tsung-Yi Lin (Cornell Tech)</div>
<div>Genevieve Patterson (MSR)</div>
<div>Matteo Ruggero Ronchi (Caltech)</div>
<div>Yin Cui (Cornell Tech)</div>
<div>Michael Maire (TTI-Chicago)</div>
<div>Ross Girshick (Facebook AI Research)</div>
<div>Piotr Doll√°r (Facebook AI Research)</div>

<h1>4. Award Committee</h1>
<div>Genevieve Patterson (MSR)</div>
<div>Matteo Ruggero Ronchi (Caltech)</div>
<div>Yin Cui (Cornell Tech)</div>
<div>Michael Maire (TTI-Chicago)</div>
<div>Serge Belongie (Cornell Tech)</div>
<div>Lubomir Bourdev (WaveOne, Inc.)</div>
<div>James Hays (Georgia Tech)</div>
<div>Pietro Perona (Caltech)</div>
<div>Deva Ramanan (CMU)</div>
